{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have already extracted the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#number of entries in this zip: 996181\n",
    "filename= \"s2-corpus-000\"\n",
    "filedir= \"/home/ricostynha/Desktop/Erasmus/Apps/FoolingAround\"\n",
    "filepath = filedir+\"/\"+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for modularity read the first 10000 entries and save in a file just to have one\n",
    "Maxentries = 100000;\n",
    "dstname = \"fist10000papers.txt\"\n",
    "dstpath = filedir+\"/\"+dstname;\n",
    "file_list = []\n",
    "dstfile= open(dstpath,\"w+\")\n",
    "with open(filepath) as infile:\n",
    "    for line in infile:\n",
    "        Maxentries-=1\n",
    "        file_list.append(line)\n",
    "        dstfile.write(line);\n",
    "        if(Maxentries==0):\n",
    "            break\n",
    "dstfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsingraw_entry(raw):\n",
    "    #year is ommisee for web pages , so it will have less fields\n",
    "    fields = ['\"entities\":','\"journalVolume\":','\"journalPages\":','\"pmid\":','\"year\":','\"outCitations\":','\"s2Url\":','\"s2PdfUrl\"',\n",
    "         '\"id\":','\"authors\":','\"journalName\":','\"paperAbstract\":','\"inCitations\":','\"pdfUrls\":',\n",
    "         '\"title\":','\"doi\":','\"sources\":','\"doiUrl\":','\"venue\":']\n",
    "    helper_list=[]\n",
    "    for field in fields:\n",
    "        match = re.search(field,raw)\n",
    "        if(match != None):\n",
    "            helper_list.append([match.group(),match.span()])\n",
    "\n",
    "    reference_list=[]\n",
    "    for i in range(0,len(helper_list)-1):\n",
    "        begin = helper_list[i][1][1]\n",
    "        end   = helper_list[i+1][1][0]\n",
    "        reference_list.append([helper_list[i][0],raw[begin:end]])\n",
    "    begin = helper_list[-1][1][1]\n",
    "    reference_list.append([helper_list[-1][0],raw[begin:]])\n",
    "    return reference_list\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basicaly ,a lot of papers dont have the filed year\n",
    "data = []\n",
    "for i in range(10000):\n",
    "    a = parsingraw_entry(file_list[i])\n",
    "    if(len(a)==19):\n",
    "        c = [b[1] for b in a]\n",
    "        data.append(c)\n",
    "    else:\n",
    "        c1 = [b[1] for b in a[0:4]]\n",
    "        c2 = [None]\n",
    "        c3 = [b[1] for b in a[4:]]\n",
    "        data.append(c1+c2+c3)\n",
    "  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titles  = ['entities','journalVolume','journalPages','pmid','year','outCitations','s2Url','s2PdfUrl',\n",
    "'id','authors','journalName','paperAbstract','inCitations','pdfUrls',\n",
    "'title','doi','sources','doiUrl','venue']\n",
    "\n",
    "df = pd.DataFrame(data,columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing empty things by none\n",
    "df = df.replace({\"[],\":None})\n",
    "df = df.replace({'\"\",':None})\n",
    "df = df.replace({':\"\"':None})\n",
    "df = df.replace({'\"\"}\\n':None})\n",
    "df = df.replace({':\"\",':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_journalVolume(string):\n",
    "    if(string == None):\n",
    "        return None\n",
    "    # removing \" \" in numbers\n",
    "    newstring = string[1:-2]\n",
    "    #can appear in multiple journal volumes\n",
    "    newstring = newstring.split(' ')\n",
    "    #diferent volumes diferent array members\n",
    "    return newstring\n",
    "def parse_journalPages_helper(string):\n",
    "    #removing \\n\n",
    "    if(string == None):\n",
    "        return None\n",
    "    string = string.replace(\" \",\"\")\n",
    "    string = string.replace(\"\\\\n\",\"\")\n",
    "    string = string[1:-2]\n",
    "    #exist weirs formations irrefular like : S6-9;discussionS26-8  \n",
    "    #(now i will parse for a range of pages)\n",
    "    match = re.search('[1-9]+-[1-9]+',string)\n",
    "    if(match != None):\n",
    "        string = string[match.span()[0]:match.span()[1]]\n",
    "        return string\n",
    "    #checking if just one page\n",
    "    match = re.search('[1-9]+',string)\n",
    "    if(match != None):\n",
    "        string = string[match.span()[0]:match.span()[1]]\n",
    "        return string\n",
    "    return string\n",
    "\n",
    "def parse_journalPages(string):\n",
    "    string = parse_journalPages_helper(string);\n",
    "    if(string!= None):\n",
    "        if(string.split('-') == []):\n",
    "            print(string,string.split('-'))\n",
    "        string = string.split('-')\n",
    "    return string\n",
    "def parse_pmid(string):\n",
    "    if(string != None):\n",
    "            string = string[1:-2]\n",
    "    return string\n",
    "def parse_year(string):\n",
    "    if(string != None):\n",
    "            string = string[0:-1]\n",
    "    return string\n",
    "def parse_outCitations(string):\n",
    "    if(string ==None):\n",
    "        return string\n",
    "    string = string[1:-2]\n",
    "    string = string.split(',')\n",
    "    for i in range(len(string)):\n",
    "        string[i] = string[i][1:-1]\n",
    "    return string\n",
    "def parse_s2Url(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    string = string[1:-2]\n",
    "    return string\n",
    "def parse_s2PdfUrl(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    string = string[2:-2]\n",
    "    return string\n",
    "def parse_id(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    string = string[1:-2]\n",
    "    return string\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_authors_helper(string):\n",
    "    string = string.replace('\"name\":','')\n",
    "    string = string.replace('\"ids\":','')\n",
    "    string = string.replace('{','')\n",
    "    string = string.replace('}','')\n",
    "    string = string.replace('\"','')\n",
    "    string = string.replace(\"'\",'')\n",
    "    \n",
    "    #separate author and id\n",
    "    string = string.split(',')\n",
    "    return string\n",
    "def parse_authors(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    string = string[:-1]\n",
    "    string = string.replace('[','')\n",
    "    string = string.replace(']','')\n",
    "    string = string.split(\"},{\")\n",
    "    for i in range(len(string)):\n",
    "        string[i] = parse_authors_helper(string[i])\n",
    "    \n",
    "def parse_journalName(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    return string[1:-2]\n",
    "def parse_paperAbstract(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    #to be able to read i must replace | for another carachter\n",
    "    string = string.replace('|','///')\n",
    "    return string[1:-2]\n",
    "\n",
    "def parse_incitations(string):\n",
    "    return parse_outCitations(string)\n",
    "\n",
    "def parse_pdfUrls(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    \n",
    "    string = string[2:-3]\n",
    "    string = string.replace('\"','')\n",
    "    string = string.replace(' ','')\n",
    "    string = string.split(',')\n",
    "    return string\n",
    "def parse_title(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    return string[1:-2]\n",
    "def parse_doi(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    return string[1:-2]\n",
    "def parse_sources(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    string = string[1:-2]\n",
    "    string = string.replace('\"','')\n",
    "    string = string.split(',')\n",
    "    return string\n",
    "def parse_doiUrl(string):\n",
    "    if(string == None):\n",
    "        return string\n",
    "    return string[1:-2]\n",
    "\n",
    "def parce_venue(string):\n",
    "    if(string==None):\n",
    "        return string\n",
    "    string = string[1:-3]\n",
    "    return string\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['journalVolume'] = df['journalVolume'].apply(parse_journalVolume)\n",
    "df['journalPages'] = df['journalPages'].apply(parse_journalPages)\n",
    "df['pmid'] = df['pmid'].apply(parse_pmid)\n",
    "df['year'] = df['year'].apply(parse_year)\n",
    "df['outCitations'] = df['outCitations'].apply(parse_outCitations)\n",
    "df['s2Url'] = df['s2Url'].apply(parse_s2Url)\n",
    "df['s2PdfUrl'] = df['s2PdfUrl'].apply(parse_s2PdfUrl)\n",
    "df['id'] = df['id'].apply(parse_id)\n",
    "df['authors'] = df['authors'].apply(parse_authors)\n",
    "df['journalName'] = df['journalName'].apply(parse_journalName)\n",
    "df['paperAbstract'] = df['paperAbstract'].apply(parse_paperAbstract)\n",
    "df['inCitations'] = df['inCitations'].apply(parse_incitations)\n",
    "df['pdfUrls'] = df['pdfUrls'].apply(parse_pdfUrls)\n",
    "df['title'] = df['title'].apply(parse_title)\n",
    "df['doi'] = df['doi'].apply(parse_doi)\n",
    "df['sources'] = df['sources'].apply(parse_sources)\n",
    "df['doiUrl'] = df['doiUrl'].apply(parse_doiUrl)\n",
    "df['venue'] = df['venue'].apply(parce_venue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/ricostynha/Desktop/first1000entries\",sep = \"|\",na_rep = \"* *\",index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
